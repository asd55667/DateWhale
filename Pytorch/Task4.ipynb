{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import os\n",
    "from torch.utils import data\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import random\n",
    "\n",
    "random.seed(20190412)\n",
    "t.manual_seed(20190412)\n",
    "t.cuda.manual_seed(20190412)\n",
    "\n",
    "\n",
    "path = '/media/wcw/SeaGate316G: Data/kaggle/data/Dogs_vs_Cats/data/'# + 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "img_shape = (3, 224, 224)\n",
    "\n",
    "def read_raw_img(path, resize, L=False):\n",
    "    img = Image.open(path)\n",
    "    if resize:\n",
    "        img = img.resize(resize)\n",
    "    if L:\n",
    "        img = img.convert('L')\n",
    "    return np.asarray(img)\n",
    "\n",
    "class DogCat(data.Dataset):\n",
    "    def __init__(self,path, batch_size, img_shape):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_shape = img_shape\n",
    "        imgs = os.listdir(path)\n",
    "        random.shuffle(imgs)\n",
    "        self.imgs = [os.path.join(path, img) for img in imgs]\n",
    "        \n",
    "        normalize = T.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                std = [0.229, 0.224, 0.225])\n",
    "        self.transforms = T.Compose([T.Resize(224), \n",
    "                                     T.CenterCrop(224),\n",
    "                                     T.ToTensor(),\n",
    "                                     normalize])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        start = index * self.batch_size\n",
    "        end = min(self.batch_size, len(self.imgs) - self.batch_size)\n",
    "        size = end - start\n",
    "        \n",
    "        img_paths = self.imgs[start:end]\n",
    "        a = t.zeros((size,) + self.img_shape, requires_grad=True)\n",
    "        b = t.zeros((size, 2), requires_grad=True)\n",
    "        \n",
    "        for i in range(size):\n",
    "#             img = read_raw_img(img_paths[i], self.img_shape[1:], L=False).transpose((2,1,0))\n",
    "            img = Image.open(img_paths[i])\n",
    "#             a[i] = t.from_numpy(img)\n",
    "            a[i] = self.transforms(img)\n",
    "            b[i] = t.Tensor([1, 0]) if 'dog' in img_paths[i].split('/')[-1].split('.')[0] else t.Tensor([0, 1])\n",
    "        return a, b\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.imgs) + self.batch_size - 1)// self.batch_size\n",
    "    \n",
    "# train = DogCat(path, 32, img_shape)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class Vgg16(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_classes=2, init_weights=True):\n",
    "        super(Vgg16, self).__init__()\n",
    "        self.features = features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        x = t.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def make_layers(cfg, mode, batch_norm=False):\n",
    "    layers = []\n",
    "    if mode == 'RGB':\n",
    "        in_channels = 3\n",
    "    elif mode == 'L':\n",
    "        in_channels = 1\n",
    "    else:\n",
    "        print('only RGB or L mode')\n",
    "        \n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 损失函数与优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = Vgg16(make_layers(cfg, 'RGB'))\n",
    "print(vgg)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = t.optim.Adam(vgg.parameters(),lr=0.1)\n",
    "\n",
    "train = DogCat(path+'train', batch_size=32, img_shape=img_shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "\n",
    "for epoch in range(1):\n",
    "    for step, (x, y_) in enumerate(train, 0):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x = x\n",
    "        y_ = y_\n",
    "        \n",
    "        y = vgg(x)\n",
    "\n",
    "\n",
    "        loss = -t.mean(y_ * t.log(y) + (1 - y_) * t.log(1 - y))\n",
    "        loss = criterion(y, y_)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "test = DogCat(path+'test', batch_size=32, img_shape=img_shape)\n",
    "\n",
    "for step, (x, y_) in enumerate(test): \n",
    "    x = x.cuda()\n",
    "    y_ = y_.cuda()\n",
    "    \n",
    "    y = vgg(x)\n",
    "    \n",
    "    acc = t.max(y, 1)[1].eq(t.max(y_, 1)[1]).sum().item()/y.shape[0]\n",
    "\n",
    "    accs.append(acc)\n",
    "    \n",
    "np.mean(accs)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
